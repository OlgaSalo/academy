# Урок 13: Стохастичний градієнт

**Огляд**

На перших двох уроках ми дізналися, як будувати повністю зв’язані мережі із наборів щільних шарів. При першому створенні всі _**ваги**_ мережі встановлюються випадковим чином - мережа ще нічого не знає. На цьому уроці ми побачимо, як тренувати нейронну мережу; ми дізнаємося, як нейронні мережі **навчаються**.

Як і у всіх завданнях машинного навчання, ми починаємо з _набору навчальних даних_:

Кожен приклад у навчальних даних складається з кількох параметрів (вхідних даних) разом із очікуваними прогнозами (вихідними даними). Навчання мережі означає коригування її вагів таким чином, щоб вона могла застосувати функції для прогнозування. Наприклад, у наборі даних 80 злаків ми хочемо створити мережу, яка зможе приймати вміст цукру, клітковини та білка в кожній каші та формувати прогноз щодо “калорійності” цієї каші. Якщо ми зможемо успішно навчити мережу робити це, її ваги повинні якимось чином відображати взаємозв'язок між цими параметрами та ціллю, як це виражено в навчальних даних.

Окрім навчальних даних, нам потрібні ще дві речі:

1. "Функція втрат", яка вимірює, наскільки якісними є прогнози мережі.
2. "Оптимізатор", який може підказати мережі, як змінювати свою вагу.

**Функція втрат**

Ми бачили, як розробити архітектуру мережі, але не бачили, як _**пояснити**_ мережі, як і яку проблему вирішити. Це робота функції втрат.

Функція втрат вимірює диспропорцію між справжнім значенням цілі та значенням, яке передбачає модель.

Різні проблеми вимагають різних функцій втрат. Ми розглядали завдання регресії, де суть полягала в тому, щоб передбачити деяке числове значення - калорії серед 80 круп чи рейтинг у якості червоного вина. Іншими завданнями регресії можуть бути прогнозування ціни на будинок або економія палива автомобіля.

Загальною функцією втрат для проблем регресії є середня абсолютна похибка або нам уже відоме `MAE`. Для кожного передбачення `y_pred`, `MAE` вимірює диспропорцію від справжньої цільової `y_true` за абсолютною різницею abs `(y_true - y_pred)`.

Загальна втрата `MAE` на наборі даних є _середнім_ значенням усіх цих абсолютних різниць.

**Оптимізатор -- Стохастичний градієнт**

Ми описали проблему, **яку** хочемо вирішити в мережі, але тепер нам потрібно сказати, **як** її вирішити. Це робота _оптимізатора_. **Оптимізатор** - це алгоритм, який регулює ваги, щоб мінімізувати втрати.

Практично всі алгоритми оптимізації, що використовуються при глибокому навчанні, належать до сімейства, яке називається **стохастичним градієнтним спуском**. Вони являють собою ітераційні алгоритми, які навчають мережу поетапно. Один крок навчання проходить так:

1. Збір деяких навчальних даних та проведення їх по мережі, щоб формувати прогнози.
2. Вимірювання втрати між прогнозами та справжніми значеннями.
3. Нарешті, регулювання ваг у напрямку, що зменшує втрати. Це повторюється знову і знову, поки втрата не стане такою маленькою, наскільки вийде.

![image.png](https://firebasestorage.googleapis.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MbjhfFkYBbYEPTQa-y0-887967055%2Fuploads%2FIzxr7zvV8aNw8Ybwg2IL%2Ffile.png?alt=media)

Кожна ітераційна вибірка навчальних даних називається мінібатч (або часто просто "батч" **batch**), тоді як повний цикл навчальних даних називається "епохою" **epoch**. Кількість епох, які ви тренуєте -- це те, скільки разів мережа проганятиме кожен набір даних навчання.

**Швидкість навчання та розмір батчу**

Швидкість навчання та розмір батчів - це два параметри, які найбільше впливають на те, як проходить навчання SGD (Stochastic Gradient Descent). Їх взаємодія часто буває філігранна, і правильний підбір цих параметрів не завжди очевидний.

На щастя, для більшості робіт не потрібно буде проводити детальний пошук гіперпараметрів, щоб отримати задовільні результати. `Adam` - це алгоритм SGD, який має адаптивну швидкість навчання, що робить його придатним для більшості проблем без будь-якої настройки параметрів (у певному сенсі це "**самонастроювання**"). **`Adam`** - чудовий оптимізатор загального призначення.

**Практика**

Лінк до датасету з оцінками якості червоних вин -- [https://drive.google.com/file/d/15XBGFVEufuMYJKRIBysUIp8CAMSk7qKm/view?usp=sharing](https://drive.google.com/file/d/15XBGFVEufuMYJKRIBysUIp8CAMSk7qKm/view?usp=sharing)

_Функція втрат та оптимізатор_

```
model.compile(
    optimizer="adam",
    loss="mae",
)
```

Зверніть увагу, що ми можемо вказати втрати та оптимізатор _рядком_.

Ви також можете отримати доступ до них безпосередньо через API Keras - якщо ви, наприклад, хочете налаштувати параметри, - але для нас за замовчуванням будуть працювати нормально.

**Звідки назва?**

> Градієнт - це вектор, який повідомляє нам, у якому напрямку повинні змінюватися ваги. Точніше, він розповідає нам, як змінити ваги, щоб швидше змінити втрати. Ми називаємо процес _**градієнтним спуском**_, оскільки він використовує градієнт, щоб опустити криву втрат до мінімуму.

**Аналіз датасету**

Тепер ми знаємо все, що нам потрібно, щоб розпочати навчання моделям глибокого навчання. Тож давайте побачимо це в дії! Ми використовуватимемо набір даних**\* Red Wine Quality.\***

Цей набір даних складається з фізіохімічних вимірювань близько 1600 португальських червоних вин. Також включено рейтинг якості кожного вина із сліпих тестів смаку. Наскільки добре ми можемо передбачити сприйману якість вина за цими вимірами?

Ми помістили всю підготовку даних до наступної комірки. Наразі ви можете зауважити, що ми змінили масштаб багатьох параметрів, щоб вони знаходился в інтервалі **\[0,1]**. Як ми обговоримо далі, нейронні мережі, як правило, мають найкращі показники, коли їх вхідні дані мають стандартизований масштаб.

```
import pandas as pd
from IPython.display import display

red_wine = pd.read_csv("/content/drive/MyDrive/winequality-red.csv") #тут вказуємо шлях до датасету на вашому диску

# ділимо дані на навчальні та перевірочні
df_train = red_wine.sample(frac=0.7, random_state=0)
df_valid = red_wine.drop(df_train.index)
display(df_train.head(4))

# Масштабуємо дo [0, 1]
max_ = df_train.max(axis=0)
min_ = df_train.min(axis=0)
df_train = (df_train - min_) / (max_ - min_)
df_valid = (df_valid - min_) / (max_ - min_)

# розділимо параметри та цілі прогнозування
X_train = df_train.drop('quality', axis=1)
X_valid = df_valid.drop('quality', axis=1)
y_train = df_train['quality']
y_valid = df_valid['quality']
```



| <p><br>fixed acidity</p> | volatile acidity | citric acid | residual sugar | chlorides | free sulfur dioxide | total sulfur dioxide | density | pH | sulphates | alcohol | quality |
| ------------------------ | ---------------- | ----------- | -------------- | --------- | ------------------- | -------------------- | ------- | -- | --------- | ------- | ------- |

| 1109 | 10.8 | 0.470 | 0.43 | 2.10 | 0.171 | 27.0 | 66.0 | 0.99820 | 3.17 | 0.76 | 10.8 | 6 |
| ---- | ---- | ----- | ---- | ---- | ----- | ---- | ---- | ------- | ---- | ---- | ---- | - |

| 1032 | 8.1 | 0.820 | 0.00 | 4.10 | 0.095 | 5.0 | 14.0 | 0.99854 | 3.36 | 0.53 | 9.6 | 5 |
| ---- | --- | ----- | ---- | ---- | ----- | --- | ---- | ------- | ---- | ---- | --- | - |

| 1002 | 9.1 | 0.290 | 0.33 | 2.05 | 0.063 | 13.0 | 27.0 | 0.99516 | 3.26 | 0.84 | 11.7 | 7 |
| ---- | --- | ----- | ---- | ---- | ----- | ---- | ---- | ------- | ---- | ---- | ---- | - |

| 487 | 10.2 | 0.645 | 0.36 | 1.80 | 0.053 | 5.0 | 14.0 | 0.99820 | 3.17 | 0.42 | 10.0 | 6 |
| --- | ---- | ----- | ---- | ---- | ----- | --- | ---- | ------- | ---- | ---- | ---- | - |

Дослідимо розмір даних:

```
print(X_train.shape)
```

(1119, 11)

&#x20;Бачимо, що дані містять 11 колонок. Помістимо це число у `input_shape`

```
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=[11]),
    layers.Dense(512, activation='relu'),
    layers.Dense(512, activation='relu'),
    layers.Dense(1),
])
```

&#x20;Тепер ми готові розпочати навчання! Ми дали команду для `Keras` одночасно подавати оптимізатору 256 рядків навчальних даних (`batch_size`) і робити це 10 разів (`epochs`).

```
history = model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    batch_size=256,
    epochs=10,
)
```

```
Epoch 1/10
5/5 [==============================] - 1s 57ms/step - loss: 0.2537 - val_loss: 0.1487
Epoch 2/10
5/5 [==============================] - 0s 26ms/step - loss: 0.1485 - val_loss: 0.1250
Epoch 3/10
5/5 [==============================] - 0s 24ms/step - loss: 0.1276 - val_loss: 0.1187
Epoch 4/10
5/5 [==============================] - 0s 23ms/step - loss: 0.1146 - val_loss: 0.1083
Epoch 5/10
5/5 [==============================] - 0s 23ms/step - loss: 0.1098 - val_loss: 0.1122
Epoch 6/10
5/5 [==============================] - 0s 24ms/step - loss: 0.1088 - val_loss: 0.1040
Epoch 7/10
5/5 [==============================] - 0s 25ms/step - loss: 0.1082 - val_loss: 0.1153
Epoch 8/10
5/5 [==============================] - 0s 23ms/step - loss: 0.1080 - val_loss: 0.1020
Epoch 9/10
5/5 [==============================] - 0s 23ms/step - loss: 0.1039 - val_loss: 0.1019
Epoch 10/10
5/5 [==============================] - 0s 26ms/step - loss: 0.1016 - val_loss: 0.1071
```

Часто кращий спосіб візуалізувати втрати - це побудувати їхній графік.

```
import pandas as pd

# конвертуй історію навчання моделі у датафрейм
history_df = pd.DataFrame(history.history)
# застосуй класичну функцію Pandas
history_df['loss'].plot();
```

![](<../../.gitbook/assets/image (99).png>)

Зверніть увагу, як знижуються втрати з плином епох. Коли крива втрат стає такою горизонтальною, це означає, що модель вивчила все, що може, і не має більше причин продовжувати навчання.
