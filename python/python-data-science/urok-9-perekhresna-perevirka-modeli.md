# Урок 9: Перехресна перевірка моделі

Машинне навчання - це ітераційний \(циклічний\) процес.

Ви будете стикатися з вибором щодо того, які прогнозувальні змінні використовувати, які типи моделей використовувати, які аргументи подавати до цих моделей і т.д. На сьогоднішній день ви робили цей вибір на основі даних, вимірюючи якість моделі через валідацію.

Але у цього підходу є деякі недоліки:

Уявіть, що у вас є набір даних із 5000 рядків. Зазвичай ви виділяєте близько 20% даних як набір даних перевірки \(тобто 1000 рядків\). Але це залишає фактор рандому у визначенні оцінок моделі. Тобто модель може добре працювати на одному наборі з 1000 рядків, навіть якщо вона буде неточною на інших 1000 рядках.

Для простоти, уявіть, що у наборі перевірки є лише 1 рядок даних. Якщо ви порівнюєте альтернативні моделі, то яка з них робить найкращі прогнози для одного набору даних - це здебільшого питання удачі!

Загалом, чим більший набір перевірок, тим менше випадковості \(він же **"шум"**\) є в нашому вимірюванні якості моделі, і тим надійнішим він буде. На жаль, ми можемо отримати великий набір перевірок, лише видаливши рядки з наших навчальних даних, а менші набори навчальних даних означають гірші моделі! Який вихід?

###  **Перехресна перевірка**

Під час _перехресної перевірки_ ми запускаємо процес моделювання на різних підмножинах даних, щоб отримати кілька показників якості моделі.

Наприклад, розділимо дані на 5 частин, кожна 20% від повного набору даних. У цьому випадку ми кажемо, що ми розбили дані на 5 **«складок»**.

![](../../.gitbook/assets/image%20%2886%29.png)

Потім ми проводимо по одному експерименту для кожної складки послідовно:

1. В експерименті 1 ми використовуємо першу складку як для _перевірки_, а все інше як _навчальні дані_. Це дає нам показник якості моделі на основі набору з інтервалом 20%.
2. В експерименті 2 ми витягуємо дані з другої складки \(і використовуємо все, крім другої складки для _навчання моделі_\). Потім набір з решти чотирьох складок використовується для отримання другої оцінки якості моделі.
3. Ми повторюємо цей процес, використовуючи кожну складку як набір перевірки. Склавши разом, виходить, що 100% даних в певний момент використовується для перевірки, і в результаті ми отримуємо показник якості моделі, який базується на всіх рядках набору даних \(навіть якщо ми не використовуємо всі рядки одночасно\)!!!

###  **Коли юзати?**

Перехресна перевірка дає більш точний показник якості моделі, що особливо важливо, якщо ви приймаєте багато модельних рішень. Однак запуск може зайняти більше часу, оскільки він оцінює кілька моделей послідовно \(по одній на кожну складку\).

Отже, враховуючи ці компроміси, коли слід використовувати кожен підхід?

1. Для малих наборів даних, де додаткове обчислювальне навантаження не є великою проблемою, тому слід запустити перехресну перевірку.
2. Для більших наборів даних достатньо одного набору перевірки. Ваш код буде працювати швидше, і у вас може бути достатньо даних, тому вам не потрібно буде повторно використовувати деякі з них.

Не існує простого порогового значення для того, що відрізняє великий чи малий набір даних. Але якщо ваша модель займає пару хвилин або менше, можливо, варто перейти на _перехресну перевірку_.

Крім того, ви можете запустити перехресну перевірку та перевірити, чи результати для кожного експерименту здаються подібними. Якщо кожен експеримент дає однакові результати, можливо, достатньо одного набору перевірки.

###  **Практика**

 _Завантаєумо дані \(як завжди\)_

```text
import pandas as pd

# Локалізовуємо дані
data = pd.read_csv('/content/drive/MyDrive/melb_data.csv')

# Вибрати параметри
cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']
X = data[cols_to_use]

# Обрати ціль для прогнозів
y = data.Price
```

Потім ми створюємо конвеєр, який використовує імпутер для заповнення відсутніх значень та модель `random forest` для прогнозування.

Хоча можливо зробити перехресну перевірку без конвеєрів, це досить складно! Використання конвеєра зробить код надзвичайно простим :\)

```text
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])
```

 Оцінки перехресної перевірки ми отримуємо за допомогою функції `cross_val_scor()` від `scikit-learn`. Ми встановлюємо кількість складок за допомогою параметра `cv`.

```text
from sklearn.model_selection import cross_val_score

# Перемнож на -1 оскільки sklearn обчислює *від'ємне* MAE
scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5,
                              scoring='neg_mean_absolute_error')

print("MAE оцінки:\n", scores)
```

```text
MAE оцінки:
 [301628.7893587  303164.4782723  287298.331666   236061.84754543
 260383.45111427]
```

Зазвичай ми хочемо єдиний показник якості моделі для порівняння альтернативних моделей. Тому, ми беремо середнє значення для експериментів.

```text
print("Середнє MAE (серед експериментів):")
print(scores.mean())
```

```text
Середнє MAE (серед експериментів):
277707.3795913405
```

