# Урок 3: перевірка моделі

Ви створили модель. Але наскільки вона якісна?

На цьому уроці ви навчитеся використовувати _перевірку моделі_ для вимірювання її якості. Вимірювання якості моделі є ключем до послідовного вдосконалення ваших моделей.

**Що таке перевірка моделі**

У майбутньому вам буде потрібно оцінити майже кожну модель, яку ви коли-небудь створите. У більшості \(хоча і не у всіх\) випадках відповідним показником якості моделі є _точність прогнозування_. Іншими словами, чи будуть прогнози моделі наближеними до того, що насправді відбувається.

Багато людей роблять величезну помилку, вимірюючи точність прогнозування. Вони роблять прогнози зі своїми `навчальними даними` та порівнюють ці прогнози з `цільовими значеннями` в навчальних даних. Скоро ви відчуєте проблему з цим підходом і як її вирішити за мить, але давайте подумаємо, як би було правильно зробити передусім:

Спочатку потрібно підсумувати якість моделі зрозумілим чином. Якщо порівняти прогнозовані та фактичні значення для 10000 будинків, ви, ймовірно, знайдете суміш хороших і поганих прогнозів. Переглядати список із 10000 прогнозованих та фактичних значень було б не дуже корисно. Нам потрібно узагальнити це в єдину метрику.

Існує багато метрик для підведення підсумків якості моделі, але ми почнемо з такої, яка називається Середня абсолютна похибка -- Mean Absolute Error \(також звана як `MAE`\). Давайте розберемо цю метрику, починаючи з останнього слова, _похибка_.

Похибка передбачення для кожного будинку:

`похибка = реальне - передбачене`

Отже, якщо будинок коштував 150 000 доларів, і ви передбачали, що він коштуватиме 100 000 доларів, похибка становить 50 000 доларів.

За допомогою метрики MAE ми приймаємо значення по модулю кожної похибки. Це перетворює кожну похибку в додатне число. Потім беремо середнє значення цих абсолютних помилок. Це наш показник якості моделі. Простою українською мовою це можна сказати як:

\|`У середньому наші прогнози відхиляються приблизно на X.`

Для розрахунку MAE нам спочатку потрібна модель. Вона вбудована в комірку внизу, яку ви можете запустити нижче:

 **Весь код з минулого заняття**

```text
import pandas as pd

# посилання до датасету з даними про будинки Мельбурну
melbourne_file_path = '/content/drive/MyDrive/melb_data.csv'

# Створіть об'єкт, який міститиме в собі наш датасет
melbourne_data = pd.read_csv(melbourne_file_path) 

######################
melbourne_data.columns

# Дані будинків Мельбурну містять пусті комірки (деякі змінні деяких характеристик будинків не були записані)
# Ми навчимося як працювати з опущеними даними згодом 
# А поки, щоб уникнути труднощів, ми не враховуватимемо ВСІ будинки, у яких є пропущені змінні

melbourne_data = melbourne_data.dropna(axis=0)

y = melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
X = melbourne_data[melbourne_features]
from sklearn.tree import DecisionTreeRegressor

# Визначте модуль. Уточніть число для random_statе, щоб гарантувати однакові результати кожен раз, коли проганятимите код
melbourne_model = DecisionTreeRegressor(random_state=1)

# Підженіть модель!
melbourne_model.fit(X, y)
```

```text
DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=1, splitter='best')
```

Тепер: обчислюємо МАЕ!

```text
from sklearn.metrics import mean_absolute_error

predicted_home_prices = melbourne_model.predict(X)
mean_absolute_error(y, predicted_home_prices)
```

1115.7467183128902

###  **Проблема з оцінками "в межах вибірки"**

Значення, яке ми щойно обчислили, можна назвати оцінкою "у вибірці". Ми використовували ту саму "вибірку" будинків що для побудови моделі, що для її оцінки. Ось чому це не корисно:

Уявіть, що на великому ринку нерухомості колір дверей не пов’язаний із ціною житла.

Однак у зразку даних, який ви використовували для побудови моделі, всі будинки із зеленими дверима були дуже дорогими. Завдання моделі полягає у пошуку моделей, які передбачають ціни на житло, тому вона побачить цю закономірність і завжди буде прогнозувати високі ціни на будинки із зеленими дверима.

Оскільки ця закономірність була отримана з навчальних даних, модель буде виглядати точною у межах навчальних даних.

Але якщо цей шаблон не виконується, коли модель бачить нові дані, модель буде дуже неточною при використанні на практиці.

Практична цінність моделей полягає саме в прогнозуванні нових даних.Найпростіший спосіб зробити це - виключити деякі дані з процесу побудови моделі, а потім використовувати їх для перевірки точності моделі на даних, яких вона раніше не бачила. Ці дані називаються _**даними перевірки.**_

###  **Час програмувати!**

Бібліотека `scikit-learn` має функцію `train_test_split` спеціально розроблену для розбиття даних на дві частини. Ми будемо використовувати деякі з цих даних як _навчальні дані_, для моделі, а інші дані будемо використовувати як _дані перевірки_ для обчислення _середньої абсолютної похибки._

Ось код:

```text
from sklearn.model_selection import train_test_split

# Тут ми розіб'ємо дані на навчальні та перевірочні: що для X та y
# Розбиття (далі: спліт) базується на основі генератора випадкових чисел.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
# Визнач нову модель:
melbourne_model = DecisionTreeRegressor()
# Піджени її
melbourne_model.fit(train_X, train_y)

# отримай прогнозовані результати на основі перевірочних даних (val_X, val_y) - від англійського слова "validation"
val_predictions = melbourne_model.predict(val_X)

#оціни похибку!
print("Середня похибка складає:")
print(mean_absolute_error(val_y, val_predictions))
```

Середня похибка складає: 277878.0512158382

